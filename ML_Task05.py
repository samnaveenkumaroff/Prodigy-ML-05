# -*- coding: utf-8 -*-
"""ML-Task05.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UDHSzCsHoikk6kj1wW6z3lttXAtJRGHn
"""

!pip install kaggle

from google.colab import files
uploaded = files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d iamsouravbanerjee/indian-food-images-dataset

!mkdir -p /content/indian_food_images_temp
!unzip indian-food-images-dataset.zip -d /content/indian_food_images_temp

import os

dataset_temp_dir = '/content/indian_food_images_temp/Indian Food Images/Indian Food Images'

for root, dirs, files in os.walk(dataset_temp_dir):
    level = root.replace(dataset_temp_dir, '').count(os.sep)
    indent = ' ' * 2 * (level)
    print('{}{}/'.format(indent, os.path.basename(root)))
    subindent = ' ' * 2 * (level + 1)
    for f in files[:5]:  # Print first 5 files in each subdirectory for preview
        print('{}{}'.format(subindent, f))

!mkdir -p /content/indian_food_images
!mv /content/indian_food_images_temp/Indian\ Food\ Images/Indian\ Food\ Images/* /content/indian_food_images/

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set dataset directory
dataset_dir = '/content/indian_food_images'

# Create ImageDataGenerator for data preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,            # Rescale pixel values to [0, 1]
    validation_split=0.2       # Splitting data into training (80%) and validation (20%)
)

# Load training and validation data
train_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(224, 224),    # Resizes all images to 224x224
    batch_size=32,             # Number of images to yield from the generator in each batch
    class_mode='categorical',  # Determines the type of label arrays that are returned (one-hot encoded)
    subset='training'          # Specifies if this generator is used for training or validation
)

validation_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Print class indices to verify
class_indices = train_generator.class_indices
class_names = list(class_indices.keys())
print("Class names:", class_names)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set dataset directory
dataset_dir = '/content/indian_food_images'

# Create ImageDataGenerator for data preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,            # Rescale pixel values to [0, 1]
    validation_split=0.2       # Splitting data into training (80%) and validation (20%)
)

# Load training and validation data
train_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(224, 224),    # Resizes all images to 224x224
    batch_size=32,             # Number of images to yield from the generator in each batch
    class_mode='categorical',  # Determines the type of label arrays that are returned (one-hot encoded)
    subset='training'          # Specifies if this generator is used for training or validation
)

validation_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Print class indices to verify
class_indices = train_generator.class_indices
class_names = list(class_indices.keys())
print("Class names:", class_names)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Initialize a Sequential model
model = Sequential()

# Add Convolutional layers
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# Flatten the output from Convolutional layers
model.add(Flatten())

# Add Fully Connected layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(class_names), activation='softmax'))  # Output layer with softmax activation for multiclass classification

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=10,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator, verbose=1)
print(f"Validation Accuracy: {accuracy * 100:.2f}%")

model.save('indian_food_classifier.h5')

!pip install tensorflow

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import numpy as np

# Load model
model = tf.keras.models.load_model('indian_food_classifier.h5')

# Define class names and calorie values
class_names = [
    'adhirasam', 'aloo_gobi', 'aloo_matar', 'aloo_methi', 'aloo_shimla_mirch', 'aloo_tikki',
    'anarsa', 'ariselu', 'bandar_laddu', 'basundi', 'bhatura', 'bhindi_masala', 'biryani', 'boondi',
    'butter_chicken', 'chak_hao_kheer', 'cham_cham', 'chana_masala', 'chapati', 'chhena_kheeri',
    'chicken_razala', 'chicken_tikka', 'chicken_tikka_masala', 'chikki', 'daal_baati_churma',
    'daal_puri', 'dal_makhani', 'dal_tadka', 'dharwad_pedha', 'doodhpak', 'double_ka_meetha',
    'dum_aloo', 'gajar_ka_halwa', 'gavvalu', 'ghevar', 'gulab_jamun', 'imarti', 'jalebi', 'kachori',
    'kadai_paneer', 'kadhi_pakoda', 'kajjikaya', 'kakinada_khaja', 'kalakand', 'karela_bharta',
    'kofta', 'kuzhi_paniyaram', 'lassi', 'ledikeni', 'litti_chokha', 'lyangcha', 'maach_jhol',
    'makki_di_roti_sarson_da_saag', 'malapua', 'misi_roti', 'misti_doi', 'modak', 'mysore_pak',
    'naan', 'navrattan_korma', 'palak_paneer', 'paneer_butter_masala', 'phirni', 'pithe', 'poha',
    'poornalu', 'pootharekulu', 'qubani_ka_meetha', 'rabri', 'ras_malai', 'rasgulla', 'sandesh',
    'shankarpali', 'sheer_korma', 'sheera', 'shrikhand', 'sohan_halwa', 'sohan_papdi', 'sutar_feni',
    'unni_appam'
]
  # Replace with your class names
calorie_values = {
    'adhirasam': 250,
    'aloo_gobi': 150,
    'aloo_matar': 180,
    'aloo_methi': 160,
    'aloo_shimla_mirch': 140,
    'aloo_tikki': 120,
    'anarsa': 200,
    'ariselu': 220,
    'bandar_laddu': 300,
    'basundi': 250,
    'bhatura': 180,
    'bhindi_masala': 160,
    'biryani': 300,
    'boondi': 120,
    'butter_chicken': 350,
    'chak_hao_kheer': 200,
    'cham_cham': 180,
    'chana_masala': 220,
    'chapati': 70,
    'chhena_kheeri': 280,
    'chicken_razala': 320,
    'chicken_tikka': 300,
    'chicken_tikka_masala': 350,
    'chikki': 150,
    'daal_baati_churma': 320,
    'daal_puri': 200,
    'dal_makhani': 250,
    'dal_tadka': 230,
    'dharwad_pedha': 180,
    'doodhpak': 200,
    'double_ka_meetha': 280,
    'dum_aloo': 220,
    'gajar_ka_halwa': 300,
    'gavvalu': 180,
    'ghevar': 250,
    'gulab_jamun': 250,
    'imarti': 200,
    'jalebi': 220,
    'kachori': 180,
    'kadai_paneer': 280,
    'kadhi_pakoda': 200,
    'kajjikaya': 220,
    'kakinada_khaja': 180,
    'kalakand': 240,
    'karela_bharta': 150,
    'kofta': 200,
    'kuzhi_paniyaram': 160,
    'lassi': 120,
    'ledikeni': 250,
    'litti_chokha': 280,
    'lyangcha': 220,
    'maach_jhol': 300,
    'makki_di_roti_sarson_da_saag': 220,
    'malapua': 180,
    'misi_roti': 150,
    'misti_doi': 160,
    'modak': 200,
    'mysore_pak': 300,
    'naan': 180,
    'navrattan_korma': 250,
    'palak_paneer': 280,
    'paneer_butter_masala': 300,
    'phirni': 200,
    'pithe': 220,
    'poha': 150,
    'poornalu': 180,
    'pootharekulu': 200,
    'qubani_ka_meetha': 250,
    'rabri': 220,
    'ras_malai': 280,
    'rasgulla': 200,
    'sandesh': 180,
    'shankarpali': 160,
    'sheer_korma': 250,
    'sheera': 180,
    'shrikhand': 200,
    'sohan_halwa': 220,
    'sohan_papdi': 180,
    'sutar_feni': 250,
    'unni_appam': 160
}

def preprocess_image(image_path):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]
    return img_array

# Example function to handle file upload and predict
def handle_file_upload(change):
    uploaded_file = next(iter(upload_button.value.values()))
    image_path = './' + uploaded_file['metadata']['name']
    with open(image_path, 'wb') as f:
        f.write(uploaded_file['content'])

    # Display uploaded image
    display(Image(filename=image_path))

    # Preprocess image (assuming you have a preprocess_image function)
    img_array = preprocess_image(image_path)

    # Predict the class
    predictions = model.predict(img_array)
    print(f'Predictions shape: {predictions.shape}')  # Debug: Print predictions shape
    print(f'Predictions values: {predictions}')      # Debug: Print predictions values

    # Assuming predictions is (1, 80) and class_names is correctly defined
    if predictions.shape[1] == len(class_names):
        predicted_class_idx = np.argmax(predictions)
        if predicted_class_idx < len(class_names):
            predicted_class = class_names[predicted_class_idx]
            calorie_value = calorie_values.get(predicted_class, 'Calorie value not found')
            # Display prediction results
            print(f'Predicted Food Item: {predicted_class}')
            print(f'Calories: {calorie_value} grams per 100g')
        else:
            print('Error: Predicted class index out of range.')
    else:
        print(f'Error: Number of predictions ({predictions.shape[1]}) does not match number of classes ({len(class_names)}).')

# Assuming upload_button is a FileUpload widget
upload_button = widgets.FileUpload()
display(upload_button)

# Register the event handler to handle file upload
upload_button.observe(handle_file_upload, names='value')